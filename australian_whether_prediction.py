# -*- coding: utf-8 -*-
"""Australian_Whether_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18BQNe37qVtSjufUZ0Gv2KcCY2TJO0bm4
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import KFold 
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

Austrilia_Rain=pd.read_csv('https://dagshub.com/Vasanthengineer4949/Rain-Prediction/raw/eb06b615384f19829093cee0f22346ac4e470dc0/weatherAUS.csv')

Austrilia_Rain.head()

Austrilia_Rain.describe()

numerical_feature = [feature for feature in Austrilia_Rain.columns if Austrilia_Rain[feature].dtypes != 'O']
discrete_feature=[feature for feature in numerical_feature if len(Austrilia_Rain[feature].unique())<25]
continuous_feature = [feature for feature in numerical_feature if feature not in discrete_feature]
categorical_feature = [feature for feature in Austrilia_Rain.columns if feature not in numerical_feature]
print("Numerical Features Count {}".format(len(numerical_feature)))
print("Discrete feature Count {}".format(len(discrete_feature)))
print("Continuous feature Count {}".format(len(continuous_feature)))
print("Categorical feature Count {}".format(len(categorical_feature)))

"""Finding and Filling Null Values"""

Austrilia_Rain.isnull().sum()

Austrilia_Rain['WindGustDir'].fillna(Austrilia_Rain['WindGustDir'].mode()[0], inplace=True)
Austrilia_Rain['WindDir9am'].fillna(Austrilia_Rain['WindDir9am'].mode()[0], inplace=True)
Austrilia_Rain['WindDir3pm'].fillna(Austrilia_Rain['WindDir3pm'].mode()[0], inplace=True)
Austrilia_Rain['RainToday'].fillna(Austrilia_Rain['RainToday'].mode()[0], inplace=True)
Austrilia_Rain['RainTomorrow'].fillna(Austrilia_Rain['RainTomorrow'].mode()[0], inplace=True)

Austrilia_Rain.isnull().sum()

"""Lable Encoding"""

categorical = [var for var in Austrilia_Rain.columns if Austrilia_Rain[var].dtype=='O']
Austrilia_Rain[categorical].head()

label_encoder = preprocessing.LabelEncoder()
Austrilia_Rain['Location']= label_encoder.fit_transform(Austrilia_Rain['Location'])
Austrilia_Rain['WindGustDir']= label_encoder.fit_transform(Austrilia_Rain['WindGustDir'])
Austrilia_Rain['WindDir9am']= label_encoder.fit_transform(Austrilia_Rain['WindDir9am'])
Austrilia_Rain['WindDir3pm']= label_encoder.fit_transform(Austrilia_Rain['WindDir3pm'])
Austrilia_Rain['RainToday']= label_encoder.fit_transform(Austrilia_Rain['RainToday'])
Austrilia_Rain['RainTomorrow']= label_encoder.fit_transform(Austrilia_Rain['RainTomorrow'])

# All categorical values is be
Austrilia_Rain[categorical].head()

Austrilia_Rain.info()

Austrilia_Rain.isnull().sum()

Austrilia_Rain = Austrilia_Rain.fillna(Austrilia_Rain.median())

Austrilia_Rain.isnull().sum()

corrmat = Austrilia_Rain.corr(method = "spearman")
plt.figure(figsize=(20,5))
#plot heat map
g=sns.heatmap(corrmat,annot=True)

for feature in continuous_feature:
    data=Austrilia_Rain.copy()
    sns.distplot(Austrilia_Rain[feature])
    plt.xlabel(feature)
    plt.ylabel("Count")
    plt.title(feature)
    plt.figure(figsize=(15,15))
    plt.show()

""" plot a boxplot for all the continuous features to see the outliers"""

for feature in continuous_feature:
    data=Austrilia_Rain.copy()
    sns.boxplot(data[feature])
    plt.title(feature)
    plt.figure(figsize=(5,5))

"""Creating Machine Learning Model"""

#spliiting data into tarining and testing
X = Austrilia_Rain.drop(['RainTomorrow','Date'], axis=1)
Y = Austrilia_Rain['RainTomorrow']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=3)

print(X.shape, X_train.shape, X_test.shape)

"""Comparing the performance of the models"""

# list of models
models = [LogisticRegression(max_iter=1000), KNeighborsClassifier(), RandomForestClassifier()]

def compare_models_train_test():

  for model in models:

    # training the model
    model.fit(X_train, Y_train)
    
    # evaluating the model
    test_data_prediction = model.predict(X_test)

    accuracy = accuracy_score(Y_test, test_data_prediction)

    print('Accuracy score of the ', model, ' = ', accuracy)

compare_models_train_test()

"""#**Cross Validation**

Creating a Function to compare the models
"""

# list of models
models = [LogisticRegression(max_iter=1000), KNeighborsClassifier(), RandomForestClassifier()]

def compare_models_cross_validation():

  for model in models:

    cv_score = cross_val_score(model, X,Y, cv=5)
    
    mean_accuracy = sum(cv_score)/len(cv_score)

    mean_accuracy = mean_accuracy*100

    mean_accuracy = round(mean_accuracy, 2)

    print('Cross Validation accuracies for ', model, '=  ', cv_score)
    print('Accuracy % of the ', model, mean_accuracy)
    print('----------------------------------------------')

compare_models_cross_validation()

"""### ***RandomForestClassifier*** Model has the highest accuracy score so we will use this model to classify our data Poins

> Indented block


"""

clf = RandomForestClassifier(n_estimators = 100) 
clf.fit(X_train, Y_train)
y_pred = clf.predict(X_test)
print()
print("ACCURACY OF THE MODEL: ", accuracy_score(Y_test, y_pred))

